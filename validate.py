"""
Script de validaci√≥n de modelo de detecci√≥n de fraude.
Carga el modelo desde MLflow y eval√∫a con datos externos de test.
"""

import os
import sys
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score,
    classification_report,
    confusion_matrix
)
import mlflow
import mlflow.sklearn

print("üîç Iniciando validaci√≥n del modelo...")

# ============================================================
# CONFIGURACI√ìN DE MLFLOW
# ============================================================

workspace_dir = os.getcwd()
mlruns_dir = os.path.join(workspace_dir, "mlruns")
tracking_uri = f"file://{os.path.abspath(mlruns_dir)}"

mlflow.set_tracking_uri(tracking_uri)
print(f"üìÅ Tracking URI: {tracking_uri}")

# ============================================================
# OBTENER √öLTIMO MODELO REGISTRADO
# ============================================================

def get_latest_run(experiment_name):
    """
    Obtiene el run m√°s reciente de un experimento.
    
    Args:
        experiment_name (str): Nombre del experimento
        
    Returns:
        str: Run ID del √∫ltimo experimento
    """
    experiment = mlflow.get_experiment_by_name(experiment_name)
    
    if experiment is None:
        print(f"‚ùå No se encontr√≥ el experimento '{experiment_name}'")
        print("Ejecuta train.py primero.")
        sys.exit(1)
    
    runs = mlflow.search_runs(
        experiment_ids=[experiment.experiment_id],
        order_by=["start_time DESC"]
    )
    
    if runs.empty:
        print("‚ùå No hay runs disponibles para validar.")
        sys.exit(1)
    
    return runs.iloc[0]

experiment_name = "fraud-detection-pipeline"
latest_run = get_latest_run(experiment_name)
run_id = latest_run['run_id']

print(f"‚úÖ Modelo encontrado - Run ID: {run_id}")
print(f"üìÖ Fecha: {latest_run['start_time']}")

# ============================================================
# CARGAR MODELO DESDE MLFLOW
# ============================================================

print(f"\nüì¶ Cargando modelo desde MLflow...")

model_uri = f"runs:/{run_id}/model"

try:
    loaded_model = mlflow.sklearn.load_model(model_uri)
    print(f"‚úÖ Modelo cargado exitosamente")
except Exception as e:
    print(f"‚ùå Error cargando modelo: {e}")
    sys.exit(1)

# ============================================================
# CARGAR DATOS DE TEST EXTERNOS
# ============================================================

def load_test_data(filepath):
    """
    Carga datos de test desde CSV externo.
    
    Args:
        filepath (str): Ruta al archivo CSV de test
        
    Returns:
        tuple: (X_test, y_test)
    """
    if not os.path.exists(filepath):
        print(f"‚ùå No se encontr√≥ el archivo: {filepath}")
        sys.exit(1)
    
    df = pd.read_csv(filepath)
    print(f"üìä Datos de test cargados: {df.shape[0]:,} filas")
    
    # Separar features y target
    X_test = df.drop('Class', axis=1)
    y_test = df['Class']
    
    # Escalar Time y Amount (igual que en entrenamiento)
    scaler = StandardScaler()
    X_test_scaled = X_test.copy()
    X_test_scaled[['Time', 'Amount']] = scaler.fit_transform(X_test[['Time', 'Amount']])
    
    print(f"üéØ Distribuci√≥n en test:")
    print(f"   - Leg√≠timas (0): {(y_test==0).sum():,} ({(y_test==0).sum()/len(y_test)*100:.2f}%)")
    print(f"   - Fraudes (1): {(y_test==1).sum():,} ({(y_test==1).sum()/len(y_test)*100:.2f}%)")
    
    return X_test_scaled, y_test

print(f"\nüì• Cargando datos de test externos...")
X_test, y_test = load_test_data('data/test_data.csv')

# ============================================================
# HACER PREDICCIONES CON DATOS EXTERNOS
# ============================================================

print(f"\nüîÆ Realizando predicciones en datos de test...")

try:
    y_pred = loaded_model.predict(X_test)
    y_pred_proba = loaded_model.predict_proba(X_test)[:, 1]
    print(f"‚úÖ Predicciones completadas")
except Exception as e:
    print(f"‚ùå Error durante predicciones: {e}")
    sys.exit(1)

# ============================================================
# CALCULAR M√âTRICAS CON DATOS EXTERNOS
# ============================================================

print(f"\nüìä Evaluando desempe√±o en datos externos...")

# Calcular todas las m√©tricas
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred_proba)

print(f"\nüìà M√âTRICAS DE VALIDACI√ìN:")
print(f"   ‚úÖ Accuracy:  {accuracy:.4f}")
print(f"   ‚úÖ Precision: {precision:.4f}")
print(f"   ‚úÖ Recall:    {recall:.4f}")
print(f"   ‚úÖ F1-Score:  {f1:.4f}")
print(f"   ‚úÖ ROC-AUC:   {roc_auc:.4f}")

# Reporte detallado
print(f"\nüìã Classification Report (Test Data):")
print(classification_report(y_test, y_pred, target_names=['Leg√≠tima', 'Fraude']))

# Matriz de confusi√≥n
cm = confusion_matrix(y_test, y_pred)
print(f"\nüî¢ Confusion Matrix:")
print(f"                 Predicted")
print(f"               Leg.  Fraud")
print(f"Actual Leg.  {cm[0][0]:6d} {cm[0][1]:6d}")
print(f"       Fraud {cm[1][0]:6d} {cm[1][1]:6d}")

# ============================================================
# VALIDACI√ìN CON UMBRALES
# ============================================================

# Umbrales para validaci√≥n
THRESHOLD_F1 = 0.10      # F1 m√≠nimo aceptable
THRESHOLD_RECALL = 0.80  # Recall m√≠nimo (importante detectar fraudes)
THRESHOLD_ROC_AUC = 0.90 # ROC-AUC m√≠nimo

print(f"\nüéØ VALIDACI√ìN DE UMBRALES:")
print(f"   {'M√©trica':<15} {'Valor':<10} {'Umbral':<10} {'Estado'}")
print(f"   {'-'*50}")

checks = [
    ('F1-Score', f1, THRESHOLD_F1),
    ('Recall', recall, THRESHOLD_RECALL),
    ('ROC-AUC', roc_auc, THRESHOLD_ROC_AUC)
]

all_passed = True
for metric_name, value, threshold in checks:
    status = "‚úÖ PASA" if value >= threshold else "‚ùå FALLA"
    if value < threshold:
        all_passed = False
    print(f"   {metric_name:<15} {value:<10.4f} {threshold:<10.2f} {status}")

# ============================================================
# DECISI√ìN FINAL
# ============================================================

print(f"\n{'='*60}")
if all_passed:
    print(f"‚úÖ MODELO VALIDADO EXITOSAMENTE")
    print(f"‚úÖ El modelo cumple todos los criterios de calidad")
    print(f"‚úÖ Apto para promoci√≥n a producci√≥n")
    sys.exit(0)
else:
    print(f"‚ùå MODELO NO CUMPLE CRITERIOS")
    print(f"‚ùå El modelo no alcanza los umbrales m√≠nimos")
    print(f"‚ùå NO apto para producci√≥n - requiere reentrenamiento")
    sys.exit(1)